{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('helper_functions')\n",
    "from get_scenarios import get_scenarios\n",
    "from plot4dist import plot4dist\n",
    "\n",
    "from model import generative_model\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario 1: 464 samples\n",
      "scenario 2: 1290 samples\n",
      "scenario 3: 1678 samples\n",
      "scenario 4: 534 samples\n",
      "scenario 5: 1254 samples\n",
      "scenario 6: 1082 samples\n",
      "scenario 7: 1007 samples\n",
      "scenario 8: 1690 samples\n",
      "scenario 9: 1001 samples\n"
     ]
    }
   ],
   "source": [
    "scenarios = get_scenarios('data/')\n",
    "Yields_columns = ['YIELD_1', 'YIELD_2', 'YIELD_3', 'YIELD_4']\n",
    "YIELDS = {key: scenarios[key][Yields_columns] for key in scenarios}\n",
    "\n",
    "for key in YIELDS:\n",
    "    print('scenario {}: {} samples'.format(key, YIELDS[key].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise shape: (100000, 50)\n",
      "scenario shape: (100000, 9)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "latent_dim = 50\n",
    "\n",
    "noise = np.random.normal(0, 1, (n_samples, latent_dim))\n",
    "print('noise shape:', noise.shape)\n",
    "\n",
    "scenario = np.zeros((n_samples, 9))  # create a vector of zeros with shape (n_samples, 9)\n",
    "for row in scenario:\n",
    "    random_idx = np.random.randint(0, 9)  # pick a random index between 0 and 8\n",
    "    row[random_idx] = 1 \n",
    "\n",
    "print('scenario shape:', scenario.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dabereabasse/anaconda3/envs/Py311/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.3.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - 0s 263us/step\n",
      "348/348 [==============================] - 0s 256us/step\n",
      "346/346 [==============================] - 0s 261us/step\n",
      "347/347 [==============================] - 0s 298us/step\n",
      "350/350 [==============================] - 0s 262us/step\n",
      "345/345 [==============================] - 0s 273us/step\n",
      "346/346 [==============================] - 0s 257us/step\n",
      "345/345 [==============================] - 0s 252us/step\n",
      "353/353 [==============================] - 0s 252us/step\n",
      "generated_data shape: (100000, 4)\n"
     ]
    }
   ],
   "source": [
    "generated_data = generative_model(noise, scenario)\n",
    "print('generated_data shape:', generated_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swds = dict()\n",
    "for scen in range(1,10):\n",
    "    # take only the samples with the i-th scenario\n",
    "    gen_data = generated_data[scenario[:, scen-1] == 1]\n",
    "    if gen_data.shape[0] > 0:\n",
    "        swds[scen] = ot.sliced_wasserstein_distance(gen_data, YIELDS[scen].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario 1: swd = 0.09241378648782211\n",
      "scenario 2: swd = 0.06958723735566726\n",
      "scenario 3: swd = 0.06969870315720766\n",
      "scenario 4: swd = 0.10628248080325144\n",
      "scenario 5: swd = 0.07329931335092643\n",
      "scenario 6: swd = 0.10262239230839387\n",
      "scenario 7: swd = 0.09325542172245106\n",
      "scenario 8: swd = 0.0707391028515526\n",
      "scenario 9: swd = 0.10282487772530385\n"
     ]
    }
   ],
   "source": [
    "for key in swds:\n",
    "    print('scenario {}: swd = {}'.format(key, swds[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise = np.load('data/noise.npy')\n",
    "output = np.load('output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
